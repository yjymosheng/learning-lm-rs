# 作业阶段

### lab 1 SiLU函数

这个比较简单.

1. 首先要提炼一个sigmoid函数 , 按照公式敲就行了.
2. 再写一个silu函数,可以方便上层理解
3. 最后拼积木拼起来就好.这个我写的不好,我对fp的理解可能会导致许多内存分配的时间效率,空间效率不理想

### lab 2 RMS Normalization

这个大概就是先寻找一些不变的量进行提取. 观察数学公式可以看出,对每一行的计算中分母都是独立唯一的,因此我们可以先把分母计算出来,用变量表示. 

1. 先计算分母,可以通过map , sum快速编写


2. 通过zip , foreach去直接表示.(这里纯粹写完就行,实际上切片的多次调用可以优化,w的指向也可以提前提取,感觉有优化的空间.实际测试运算大概10µs,以后看情况吧)


### lab 3 矩阵乘法

我原本想将转置的tensor保存下来,但是观察了一下转置的表示(原谅我线代全忘了),我选择给tensor添加一个get方法.

1. 先理清楚如何取得a,b的element (根据row, col) . 我选择实现一个tensor.get 

2. 为c的每一个element的更改实现get_mut .方便进行更改元素数据



# 项目阶段